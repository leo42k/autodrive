---
title: "angle_accel_prediction_160926"
author: "Zeyi Wang"
date: "September 27, 2016"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
library(MASS)
library(Rcpp)
library(RcppArmadillo)
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "..")
```

## 0. Quantitative question

- The original one: Can we design a self-driving car?

- Last week: Can we predict the appropriate acceleration and steering angle based on data collected by the camera and GPS, such as speed, acceleration, steering angle and camera images?

- This week: Can we predict the appropriate angle acceleration based on image data?

## 1. Recap & the goal for his week

45 GB compressed, 80 GB uncompressed (unzip it in Windows 10, not Mac OS)

```{r list.files}
list.files(file.path("comma-dataset"), recursive = T)
```

We are taking the shortest video as the target subset. 

```{r h5 package, message=FALSE, warning=FALSE}
library("h5")
log <- H5File(file.path("comma-dataset", "log", "2016-06-08--11-46-01.h5"))
image <- H5File(file.path("comma-dataset", "camera", "2016-06-08--11-46-01.h5"))
log_names <- list.datasets(log, recursive = TRUE)
image_names <- list.datasets(image, recursive = TRUE)
```

### 1.1 Image Data

The dimension is **Frames * RGB * Columns * Rows**. 

Image data are basically **4 d arrays**.

Again, check the start/end points of training/test data. 


```{r, message=FALSE}
library(imager)
par(mfrow = c(2, 2))  
plot(as.cimg(aperm(image[image_names][10001,,,], c(4,3,1,2))))  #the start of training set
plot(as.cimg(aperm(image[image_names][13001,,,], c(4,3,1,2))))  #the end of training set
plot(as.cimg(aperm(image[image_names][14002,,,], c(4,3,1,2))))  #the start of test set
plot(as.cimg(aperm(image[image_names][15002,,,], c(4,3,1,2))))  #the end of test set
par(mfrow = c(1, 1))  
```

### 1.2 Log Data

reference: [link to comma.ai github](https://github.com/commaai/research/blob/master/Logs.md)

```{r}
log_names
```

There are speed[28], acceleration[14], steering angle[35], steering torque[36]. 

####Loading the timeline, speed, accleration, angle, angle acceleration data:

```{r loading}
temp <- log[log_names[28]]@dim
speed <- log[log_names[28]][1:temp]
rm(temp)
temp <- log[log_names[14]]@dim
accel <- log[log_names[14]][1:temp]
rm(temp)
accel_tri <- 1 * (accel > 0.8) - 1 * (accel < - 0.8)  #this is the "answer" for supervised learning
library(scales)
temp <- log[log_names[35]]@dim
angle <- log[log_names[35]][1:temp]
rm(temp)
angle <- scale(angle)
temp <- log[log_names[36]]@dim
angle_accel <- log[log_names[36]][1:temp]
rm(temp)
angle_accel <- rescale(angle_accel, to = c(-1, 1))
temp <- log[log_names[13]]@dim
timeline_image <- log[log_names[13]][1:temp]
rm(temp)


hist(angle_accel)
```

We rescaled the angle acceleration to (-1,1)

### 1.3 Goal
- Using image data to predict angle acceleration

## 2. This week
- Transform the image data into angles of the lines on the road

### 2.1 Method
- We take a smaller subset
- For each timepoint, we predict the angle acceleration based on 5 sec images
- For each images, we stamp out the lines on the road
- We fit the lines for left/right part seperately, record the coefficient
- 10 coefficients (2 for each image) consist the predictor for 1 timepoint

### 2.2 Step by step:

We take the timepoint 60000 as an example:

- We first take the image:

```{r}
timeline_image[60000]  #align the timelines for image and log
M <- aperm(image[image_names][12001,,,], c(4,3,1,2))
plot(as.cimg(M))
```

- Then we stamp out the lines

```{r}
MM <- (M[,,1,1]>=180)&(M[,,1,2]>=180)&(M[,,1,3]>=180)
MMM <- M
for (i in 1:3) {
    MMM[,,1,i] <- MM*M[,,1,i]
}
plot(as.cimg(MMM))
```

- Then we get the coefficients: 

```{r echo=FALSE}
get.angle <- function(k) {
temp.M <- image[image_names][k,,,]
# temp.MM <- (0.212671*temp.M[1,1,,]+0.715160*temp.M[1,2,,]+0.072169*temp.M[1,3,,]>240)
temp.MM <- t((temp.M[1,1,,]>180)&(temp.M[1,2,,]>180)&(temp.M[1,3,,]>180))
# temp.MM <- t(as.matrix(temp.MM))
temp1 <- which(temp.MM[1:160,] == 1, arr.ind = T)
temp2 <- which(temp.MM[161:320,] == 1, arr.ind = T)
rm(temp.MM, temp.M)
if (length(unique(temp1[,1])) > 1 ) {
    c1 <- coef(fastLmPure(cbind(1,temp1[,1]),temp1[,2]))[2]
} else {
    c1 <- 1
}
if (length(unique(temp2[,1])) > 1 ) {
    c2 <- coef(fastLmPure(cbind(1,temp2[,1]),temp2[,2]))[2]
} else {
    c2 <- 1
}
rm(temp1, temp2)
return(c(c1, c2))
}
```


```{r}
k <- 12001
temp.M <- image[image_names][k,,,]
# temp.MM <- (0.212671*temp.M[1,1,,]+0.715160*temp.M[1,2,,]+0.072169*temp.M[1,3,,]>240)
temp.MM <- t((temp.M[1,1,,]>180)&(temp.M[1,2,,]>180)&(temp.M[1,3,,]>180))
# temp.MM <- t(as.matrix(temp.MM))
temp1 <- which(temp.MM[1:160,] == 1, arr.ind = T)
temp2 <- which(temp.MM[161:320,] == 1, arr.ind = T)
rm(temp.MM, temp.M)
plot(temp1)
abline(fastLmPure(cbind(1,temp1[,1]),temp1[,2]))
plot(temp2)
abline(fastLmPure(cbind(1,temp2[,1]),temp2[,2]))
```

- Using RcppArmadillo to make it faster
```{r}
get.angle(12001)
```


- Then we build up the training/validation/test set based on this method

```{r, message=FALSE}

set.seed(160926)
index_train <- sample(50001:65000, size = 10000)
index_validation <- setdiff(50001:65000, index_train)
index_test <- 70001:75000


library(randomForest)
set_train <- readRDS(file.path("temp", "set_train_angle.rds"))
set_validation <- readRDS(file.path("temp", "set_validation_angle.rds"))
set_test <- readRDS(file.path("temp", "set_test_angle.rds"))


model <- randomForest(set_train[,2:11], set_train[,1])
mean((predict(model, set_train[,2:11]) - set_train[,1])^2)  #validation MSE
mean((predict(model, set_validation[,2:11]) - set_validation[,1])^2)  #validation MSE
mean((predict(model, set_test[,2:11]) - set_test[,1])^2)  #test MSE

```

We can check on the test set that it is not simulating going forward

```{r}
hist(predict(model, set_test[,2:11]))
```



## 3. Tasks remained

### 3.1 Image processing
- outliers detection

### 3.2 GPS/radar/lidar data
There could be two reasons 

- when there is no lines, we cannot just go straight forward

- radar/lidar can do a better job then image on detecting cars/walls/people in front

But we need the code book for log
```{r}
log_names
```

### 3.3 Visualization
There is a code for visualization on comma.ai github

### 3.4 Better encoder and deep learning method
The current method is equivalent to encode each image into just two numbers. 

A better encoder could be used so that we could apply more advanced learning method. 

Key information (without deep learning from images): 

Where are the lines; 

What is the direction provided by gps;

Whether there is car in front provided by radar/lidar; 

Whether there is car at rear left/right for changing lanes

Key information (learn from images):

a better encoder

Adjusted goal for this project (without a better encoder or deep learning method):

- Appropriately driving on a shiny day on highway; 

- i.e. predicting speed/angle acceleration based on image with relatively clear lines. 