---
title: "rf_with_vanishing_point"
author: "Zeyi Wang"
date: "October 21, 2016"
output: html_document
---


```{r setup, include=FALSE}
library(knitr)
library(MASS)
library(Rcpp)
library(imager)
library(dplyr)
library(animation)
library(PET)
library(raster)
library(scales)
library(MASS)
library(pracma)  # cot
library("h5")
library(dlm)
library(RcppArmadillo)
library(adimpro)
library(randomForest)
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "..")
```

```{r h5 package, message=FALSE, warning=FALSE, echo=FALSE}
source(file.path("code", "draw_path_on.R"))
source(file.path("code", "hough.R"))

log <- H5File(file.path("comma-dataset", "log", "2016-06-08--11-46-01.h5"))
image <- H5File(file.path("comma-dataset", "camera", "2016-06-08--11-46-01.h5"))
log_names <- list.datasets(log, recursive = TRUE)
image_names <- list.datasets(image, recursive = TRUE)

temp <- log[log_names[28]]@dim
speed <- log[log_names[28]][1:temp]
rm(temp)
temp <- log[log_names[35]]@dim
angle <- log[log_names[35]][1:temp]
rm(temp)
angle <- angle/10
temp <- log[log_names[13]]@dim
timeline_image <- log[log_names[13]][1:temp]
rm(temp)
# speed, angle, timeline

index_train <- 11000:13000
index_test <- 13001:14400

set_train <- readRDS(file.path("temp", "set_train.rds"))
set_test <- readRDS(file.path("temp", "set_test.rds"))
model <- readRDS(file.path("temp", "model.rds"))

predicted.angle <- predict(model, set_test[,2:4])
predicted.angle.train <- predict(model, set_train[,2:4])
```


## 0. Scope of the self-driving problem, revisit

- We focus on __image processing__:
    + human drivers don't need lidar
    + gps and lidar adjustment

- Main challenges: 
    + vanishing point
    + vehicle detection [for lane changing, heavy traffic]
    
- Problem of interest: 
    + __steering angle__ prediction
    + __robust vanishing point detection__ as an estimator
    + for lower traffic complexity, highway mainly [lane markings]

- Not of interest: 
    + traffic signs [particle filters]
    + lane changing [deep learning or lidar + markings detection + vehicle detection]
    + driving route [gps]

```{r echo=FALSE}
i <- 595
k <- index_train[i]
plot(as.cimg(aperm(image[image_names][k,,,], c(4,3,1,2))))
draw_path_on(speed_ms = set_train[i, 2], angle_steers = set_train[i,1], color = "blue")
draw_path_on(speed_ms = set_train[i, 2], angle_steers = predicted.angle.train[i], color = "green")
points((set_train[i,3] + 0.5) * 320, 160 - ((set_train[i,4] + 0.5) * 320 - 160), col = "red", pch=19, cex=1.5)
```

# Methods

#### _Data Collection_

We use the driving dataset shared by [comma.ai](https://github.com/commaai/research) on July 2016. We downloaded it on September 17, 2016. 

Data was collected by an Acura ILX 2016, including video clips 20 Hz and log information for speed, acceleration, steering angle, etc. at 100Hz. Both were recorded to a same timeline. 

#### _Exploratory Analysis_

#### _Statistical Methods_

##### __1. Edge detection and greyscale__

For each frame from the original video, a Sobel filter is applied as the first step. The benefit of Sobel is simplicity and fast computing. 

The image is then tranformed into greyscale so that we could filter for markings.

```{r}
i <- 595
k <- index_train[i]
image_use <- (as.cimg(aperm(image[image_names][k,,,], c(4,3,1,2))))
result <- edges( make.image(image_use[,160:1,1,]), type = "Sobel")
result <- rgb2grey(result)
plot(image_use)
show.image(result)
```

##### __2. Dynamic lane detection__

A 97% quantile threshold is applied for dynamic lane detection. 

```{r}
temp.M <- extract.image(result)
temp.MM <- (temp.M > quantile(temp.M, 0.97))*1
show.image(make.image(temp.MM))
temp <- which(temp.MM == 1, arr.ind = T)
```

##### __3. Hough transformation__

To get robust vanishing point estimation, we first apply hough transformation to left/right part of the preprocessed image, seperately. 

```{r echo=FALSE}
temp1 <- temp[(temp[,2] > 25)&(temp[,1] <=160), ]
temp2 <- temp[(temp[,2] > 25)&(temp[,1] >160), ]
P <- matrix(0, 320, 320)
P[temp1] <- 1
getLineHough_plot(P)
P <- matrix(0, 320, 320)
P[temp2] <- 1
getLineHough_plot(P)
```

Combine together we have:

```{r echo=FALSE}
P <- matrix(0, 320, 320)
P[temp] <- 1
p <- P
length.row <- nrow(p)
abc=hough(p)
houghParam<-unlist(abc$Header)
image(p,main="original")
P1 <- matrix(0, 320, 320)
P1[temp1] <- 1
getLineHough_plotline(P1)
P2 <- matrix(0, 320, 320)
P2[temp2] <- 1
getLineHough_plotline(P2)

point <- get.vanishing.point(k)
points(point[1]+0.5, point[2], pch = 19, col = "blue")
```

# Visualization